# Guide de G√©n√©ration du Dataset Q&A

## üìã R√©sum√© Ex√©cutif

Ce document d√©crit la g√©n√©ration d'un **dataset Q&A combin√© unique** (`deepsynth-qa`) qui regroupe Natural Questions et MS MARCO en un seul dataset avec images pr√©-g√©n√©r√©es.

### D√©cisions Cl√©s

‚úÖ **UN SEUL DATASET COMBIN√â** plut√¥t que plusieurs datasets s√©par√©s
- Meilleur pour le training multi-domaine
- Batch mixing automatique
- Tra√ßabilit√© pr√©serv√©e via `metadata.source`

‚úÖ **G√âN√âRATION ONE-SHOT** directe (pas de datasets interm√©diaires √† merger)
- Traitement s√©quentiel Natural Questions ‚Üí MS MARCO
- Upload incr√©mental dans un seul dataset final
- Interruption/reprise support√©e

‚úÖ **IMAGES PR√â-G√âN√âR√âES** √† r√©solution gundam (1600px)
- 0% overhead pendant le training
- Downscale possible vers tiny/base si besoin
- Extraction contextuelle intelligente

---

## üéØ Composition du Dataset Final

### `deepsynth-qa` (~1.3M samples)

| Source | Samples | Caract√©ristiques | Qualit√© Moyenne |
|--------|---------|------------------|-----------------|
| **Natural Questions** | ~300k | Documents longs (avg 8,907 tokens) <br> Extraction contextuelle intelligente <br> Long answer priority | 70% excellent <br> 25% good |
| **MS MARCO** | ~1M | Documents courts (avg 200-500 tokens) <br> Pas d'extraction n√©cessaire <br> Short answers | 95%+ excellent |

**Total**: ~1.3M samples Q&A multilingues et multi-formats

---

## üìä Taille Estim√©e du Dataset

### Natural Questions (300k samples)
```
Documents apr√®s extraction: ~1,500 tokens moyenne
Image gundam: 1600√ó1500px √ó 3 (RGB) ‚âà 7.2 MB/sample
Total non-compress√©: 300k √ó 7.2 MB ‚âà 2.16 TB
Compress√© PNG (5-10x): 216-432 GB
```

### MS MARCO (1M samples)
```
Documents courts: ~200 tokens moyenne
Image gundam: 1600√ó200px √ó 3 (RGB) ‚âà 960 KB/sample
Total non-compress√©: 1M √ó 960 KB ‚âà 960 GB
Compress√© PNG (5-10x): 96-192 GB
```

### üéØ Total Estim√©: **312-624 GB compress√© sur HuggingFace**

C'est g√©rable! HuggingFace supporte des datasets bien plus larges.

---

## üöÄ Utilisation

### 1Ô∏è‚É£ Test Rapide (Recommand√© pour d√©buter)

```bash
# Test avec 1000 samples par source (~2 minutes)
./generate_qa_dataset.sh --test

# Test avec nombre personnalis√©
./generate_qa_dataset.sh --max-samples 5000
```

### 2Ô∏è‚É£ G√©n√©ration Production Compl√®te

```bash
# G√©n√©ration compl√®te (~6-12 heures)
./generate_qa_dataset.sh

# Ou directement avec Python
PYTHONPATH=./src python3 generate_qa_dataset.py
```

### 3Ô∏è‚É£ Options Avanc√©es

```bash
# Seulement Natural Questions
python3 generate_qa_dataset.py --skip-marco

# Seulement MS MARCO
python3 generate_qa_dataset.py --skip-nq

# Custom samples pour chaque source
python3 generate_qa_dataset.py --nq-samples 50000 --marco-samples 100000

# R√©solution diff√©rente
python3 generate_qa_dataset.py --resolution base

# Batch size personnalis√©
python3 generate_qa_dataset.py --batch-size 10000
```

---

## üì¶ Structure du Dataset

### Sch√©ma des Samples

```python
{
    # Document et instruction
    "text": "DOCUMENT COMPLET (8,907 tokens pour NQ)",
    "instruction": "when is the last episode of walking dead season 8?",

    # R√©ponses
    "answer": "The eighth season premiered..." (LONG priority),
    "short_answer": "March 18, 2018",
    "long_answer": "The eighth season premiered...",

    # Positions (pour extraction future si besoin)
    "answer_start_token": 2114,
    "answer_end_token": 3538,

    # Image PR√â-G√âN√âR√âE
    "image": <PIL.Image 1600√ó2224px>,

    # Qualit√©
    "quality": "excellent",
    "estimated_height": 2224,
    "token_count": 8907,  # Document COMPLET
    "extracted_token_count": 2224,  # Ce qui est dans l'image

    # Metadata avec ORIGINE
    "metadata": {
        "source": "natural_questions",  # ‚Üê TRA√áABILIT√â
        "original_index": 42,
        "answer_type": "long",
        "has_short": true,
        "has_long": true,
        "extraction_method": "contextual",
        "context_window": 800,
        "generation_resolution": "gundam",
        "quality_description": "Optimal readability (‚â§2200px)"
    }
}
```

### Filtrage par Source

```python
from datasets import load_dataset

# Charger dataset complet
dataset = load_dataset("baconnier/deepsynth-qa", split="train")

# Filtrer Natural Questions seulement
nq_dataset = dataset.filter(
    lambda x: x["metadata"]["source"] == "natural_questions"
)

# Filtrer MS MARCO seulement
marco_dataset = dataset.filter(
    lambda x: x["metadata"]["source"] == "ms_marco"
)

# Statistiques par source
from collections import Counter
sources = Counter(sample["metadata"]["source"] for sample in dataset)
print(sources)  # {'natural_questions': 300k, 'ms_marco': 1M}
```

---

## üîß Architecture d'Impl√©mentation

### Flux de G√©n√©ration One-Shot

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ G√âN√âRATION ONE-SHOT (generate_qa_dataset.py)           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  1Ô∏è‚É£ Initialize IncrementalDatasetUploader              ‚îÇ
‚îÇ     ‚îú‚îÄ HuggingFace repo: deepsynth-qa                  ‚îÇ
‚îÇ     ‚îú‚îÄ Batch size: 5000                                ‚îÇ
‚îÇ     ‚îî‚îÄ Duplicate tracking: (source, original_index)    ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  2Ô∏è‚É£ Process Natural Questions                          ‚îÇ
‚îÇ     ‚îú‚îÄ convert_natural_questions(streaming=True)       ‚îÇ
‚îÇ     ‚îú‚îÄ Intelligent contextual extraction               ‚îÇ
‚îÇ     ‚îú‚îÄ Pre-generate images (gundam 1600px)            ‚îÇ
‚îÇ     ‚îú‚îÄ Set metadata.source = "natural_questions"      ‚îÇ
‚îÇ     ‚îî‚îÄ Upload batches incrementally (every 5k)        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  3Ô∏è‚É£ Process MS MARCO                                   ‚îÇ
‚îÇ     ‚îú‚îÄ convert_ms_marco(streaming=True)                ‚îÇ
‚îÇ     ‚îú‚îÄ No extraction (docs already short)              ‚îÇ
‚îÇ     ‚îú‚îÄ Pre-generate images (gundam 1600px)            ‚îÇ
‚îÇ     ‚îú‚îÄ Set metadata.source = "ms_marco"               ‚îÇ
‚îÇ     ‚îî‚îÄ Upload batches incrementally (every 5k)        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  4Ô∏è‚É£ Result: Single combined dataset                    ‚îÇ
‚îÇ     ‚îî‚îÄ deepsynth-qa with ~1.3M samples                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Algorithme d'Extraction Intelligente

```python
# Pour chaque document Natural Questions:

1. Calculer token_count du document COMPLET

2. D√©cider strat√©gie:
   should_extract, window = should_extract_context(
       token_count,
       target_resolution="gundam"
   )

   # Seuil: max(2000, context_window * 2)
   # Pour gundam: max(2000, 800*2) = 2000

3. Si should_extract == False (doc ‚â§ 2000 tokens):
   ‚Üí Utiliser document ENTIER pour l'image
   ‚Üí extraction_method = "full_document"

4. Si should_extract == True (doc > 2000 tokens):
   ‚Üí Extraire ¬±800 tokens autour de la r√©ponse
   ‚Üí extraction_method = "contextual"

5. G√©n√©rer image √† r√©solution gundam (1600px)

6. Stocker:
   - "text": Document COMPLET (flexibilit√©)
   - "image": Image PR√â-G√âN√âR√âE
   - "token_count": Taille COMPL√àTE
   - "extracted_token_count": Ce qui est dans l'image
```

---

## üìà Avantages de l'Approche Combin√©e

### ‚úÖ Training Multi-Domaine

**Batch Mixing Automatique**:
```python
# Un batch contient naturellement un mix de sources
batch = [
    sample_nq_1,      # Natural Questions (long-form)
    sample_marco_1,   # MS MARCO (short)
    sample_nq_2,      # Natural Questions
    sample_marco_2,   # MS MARCO
    ...
]
# ‚Üí Meilleure g√©n√©ralisation cross-domaine
```

### ‚úÖ Gestion Simplifi√©e

```python
# UN SEUL dataset √† charger
from datasets import load_dataset
dataset = load_dataset("baconnier/deepsynth-qa")

# VS plusieurs datasets s√©par√©s
nq_dataset = load_dataset("baconnier/deepsynth-nq")
marco_dataset = load_dataset("baconnier/deepsynth-marco")
# ... puis merge manuel
```

### ‚úÖ Flexibilit√© Pr√©serv√©e

```python
# Filtrer par qualit√©
excellent_samples = dataset.filter(lambda x: x["quality"] == "excellent")

# Filtrer par source
nq_only = dataset.filter(lambda x: x["metadata"]["source"] == "natural_questions")

# Filtrer par type de r√©ponse
long_answers = dataset.filter(lambda x: x["metadata"]["has_long"])

# Filtrer par extraction
contextual = dataset.filter(lambda x: x["metadata"]["extraction_method"] == "contextual")
```

---

## üîç Validation

### Test de l'Impl√©mentation

```bash
# Valider l'impl√©mentation
PYTHONPATH=./src python3 test_qa_implementation.py
```

**R√©sultats Attendus**:
```
‚úÖ ALL TESTS PASSED!

Implementation validated:
  ‚úì Images pre-generated at gundam resolution (1600px)
  ‚úì Intelligent contextual extraction
  ‚úì Full document stored in 'text' field
  ‚úì Answer positions stored
  ‚úì Dataset origin metadata properly set
  ‚úì Quality indicators calculated
```

### V√©rifier le Dataset G√©n√©r√©

```python
from datasets import load_dataset

# Charger dataset
dataset = load_dataset("baconnier/deepsynth-qa", split="train")

# V√©rifier composition
from collections import Counter
sources = Counter(sample["metadata"]["source"] for sample in dataset)
print(f"Natural Questions: {sources['natural_questions']:,}")
print(f"MS MARCO: {sources['ms_marco']:,}")

# V√©rifier images pr√©-g√©n√©r√©es
sample = dataset[0]
assert sample["image"] is not None, "Image should be pre-generated"
print(f"Image size: {sample['image'].size}")  # (1600, height)

# V√©rifier metadata
assert "source" in sample["metadata"]
assert "generation_resolution" in sample["metadata"]
assert sample["metadata"]["generation_resolution"] == "gundam"
```

---

## üéì FAQ

### Q: Pourquoi un seul dataset plut√¥t que plusieurs?

**R**: Batch mixing automatique ‚Üí meilleure g√©n√©ralisation. Le champ `metadata.source` permet de filtrer par source si n√©cessaire, donc vous gardez toute la flexibilit√©.

### Q: Combien de temps pour g√©n√©rer?

**R**:
- Test (1k samples/source): ~5-10 minutes
- Production compl√®te (~1.3M): 6-12 heures

### Q: Quelle taille finale?

**R**: 312-624 GB compress√© sur HuggingFace (g√©rable).

### Q: Puis-je interrompre et reprendre?

**R**: Oui! L'upload incr√©mental track les progress. Ctrl+C puis relancer le script.

### Q: Comment filtrer par source pendant le training?

**R**:
```python
# Option 1: Filtrer avant le training
nq_dataset = dataset.filter(lambda x: x["metadata"]["source"] == "natural_questions")

# Option 2: Stratified sampling
from torch.utils.data import WeightedRandomSampler
weights = [2.0 if x["metadata"]["source"] == "natural_questions" else 1.0
           for x in dataset]
sampler = WeightedRandomSampler(weights, len(dataset))
```

### Q: Les images sont-elles vraiment pr√©-g√©n√©r√©es?

**R**: OUI! Contrairement √† l'ancienne approche (g√©n√©ration √† la vol√©e), les images sont maintenant g√©n√©r√©es UNE FOIS pendant la cr√©ation du dataset et stock√©es sur HuggingFace. Training overhead = 0%.

### Q: Que contient le champ "text"?

**R**: Le document COMPLET (pas l'extrait). Pour Natural Questions, c'est le document original de 8,907 tokens en moyenne. L'extraction contextuelle est seulement pour l'image.

---

## üìö R√©f√©rences

- [QA_FINAL_IMPLEMENTATION_PLAN.md](./QA_FINAL_IMPLEMENTATION_PLAN.md) - Plan d√©taill√© d'impl√©mentation
- [QA_QUALITY_INDICATORS_IMPLEMENTATION.md](./QA_QUALITY_INDICATORS_IMPLEMENTATION.md) - Indicateurs de qualit√©
- [QA_STREAMING_IMPLEMENTATION.md](./QA_STREAMING_IMPLEMENTATION.md) - Streaming dataset support
- [PRODUCTION_GUIDE.md](./PRODUCTION_GUIDE.md) - Guide de d√©ploiement production

---

**Document Version**: 1.0
**Date**: 2025-10-28
**Auteur**: DeepSynth Team
**Status**: ‚úÖ Impl√©mentation compl√®te et test√©e
