# PRD DeepSeek-OCR : Fine-Tuning pour R√©sum√© Abstractif

## üìã Vue d'ensemble du Projet

**Objectif** : Fine-tuner uniquement le d√©codeur DeepSeek-OCR (570M param√®tres actifs) pour g√©n√©rer des r√©sum√©s abstractifs √† partir de documents compress√©s visuellement √† 20x.

**Architecture Cible** :
```
Texte/PDF ‚Üí Image 2D ‚Üí DeepEncoder (frozen, 380M) ‚Üí Tokens Visuels 20x ‚Üí D√©codeur MoE (fine-tuned, 570M) ‚Üí R√©sum√©
```

## üîó R√©f√©rences Officielles

### Code Source
- **Repo GitHub Principal** : https://github.com/deepseek-ai/DeepSeek-OCR
- **HuggingFace Model** : https://huggingface.co/deepseek-ai/DeepSeek-OCR
- **Paper ArXiv** : https://arxiv.org/abs/2510.18234
- **Code Modeling** : https://huggingface.co/deepseek-ai/DeepSeek-OCR/blob/main/modeling_deepseekocr.py

### Guides d'Installation
- **Guide Complet 2025** : https://skywork.ai/blog/ai-agent/how-to-install-run-deepseek-ocr-2025-guide/
- **vLLM Integration** : https://docs.vllm.ai/projects/recipes/en/latest/DeepSynth/DeepSeek-OCR.html
- **Simon Willison Demo** : https://simonwillison.net/2025/Oct/20/deepseek-ocr-claude-code/

## üìä Datasets Hugging Face

### R√©sum√© de Documents
| Dataset | URL HF | Champs | Taille | Usage |
|---------|--------|---------|---------|-------|
| CNN/DailyMail | `ccdv/cnn_dailymail` | `article`, `highlights` | 287k train | Principal |
| XSum | `EdinburghNLP/xsum` | `document`, `summary` | 204k train | Extr√™me |
| arXiv | `ccdv/arxiv-summarization` | `article`, `abstract` | Variable | Scientifique |
| Gigaword | `gigaword` | `document`, `summary` | 3.8M | Titres |
| FINDSum | `trigaten/findsum` | Multiple | 21k | Finance |

### Vision-Document
| Dataset | URL HF | Description | Usage |
|---------|--------|-------------|-------|
| Docmatix | `HuggingFaceM4/Docmatix` | 2.4M images, 9.5M Q/A | DocVQA |
| DocVQA | `docvqa` | 50k questions sur docs | OCR+QA |
| Document Haystack | `AmazonScience/document-haystack` | 400 variants, long docs | Multi-page |
| OmniDocBench | `opendatalab/OmniDocBench` | Benchmark diversifi√© | √âvaluation |

## üèóÔ∏è Architecture Technique

### Composants
1. **DeepEncoder** (380M params) : SAM + CLIP + Compression 16x
2. **Espace Latent** : Tokens visuels compress√©s (64-400 tokens selon mode)  
3. **D√©codeur MoE** (570M params actifs sur 3B total) : Generation de texte

### Configuration Compression 20x
- **Pr√©cision OCR** : ~60% (acceptable pour r√©sum√©)
- **Ratio Information** : 1 token visuel ‚âà 20 tokens texte
- **Avantage** : Perte d'info = abstraction naturelle

## ‚öôÔ∏è Setup Environnement

### Pr√©requis
```bash
Python >= 3.9
CUDA >= 11.8
GPU: 16GB+ recommand√© (RTX 4090, A100)
RAM: 32GB+ recommand√©
```

### Installation
```bash
# Clone du repo officiel
git clone https://github.com/deepseek-ai/DeepSeek-OCR
cd DeepSeek-OCR

# Installation d√©pendances
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install transformers>=4.46.0 tokenizers>=0.20.0
pip install datasets accelerate
pip install flash-attn --no-build-isolation
pip install -r requirements.txt

# Login Hugging Face pour datasets
huggingface-cli login
# Token depuis: https://huggingface.co/settings/tokens
```

## üíæ Pr√©paration des Donn√©es

### Exemple CNN/DailyMail
```python
from datasets import load_dataset
from PIL import Image, ImageDraw, ImageFont
import textwrap

# Chargement dataset
dataset = load_dataset("ccdv/cnn_dailymail", "3.0.0")

def text_to_image(text, max_width=1800, max_height=2400):
    """Convertit texte en image PNG"""
    font = ImageFont.truetype("/usr/share/fonts/truetype/arial.ttf", 20)
    
    # Wrap text pour largeur
    lines = []
    for paragraph in text.split('\n'):
        wrapped = textwrap.fill(paragraph, width=80)
        lines.extend(wrapped.split('\n'))
    
    # Calcul dimensions
    line_height = 25
    img_height = min(len(lines) * line_height + 40, max_height)
    
    # Cr√©ation image
    img = Image.new('RGB', (max_width, img_height), color='white')
    draw = ImageDraw.Draw(img)
    
    y = 20
    for line in lines[:90]:  # Limite pour √©viter images trop grandes
        draw.text((20, y), line, font=font, fill='black')
        y += line_height
        
    return img

# Exemple usage
sample = dataset['train'][0]
img = text_to_image(sample['article'])
img.save('document.png')
target_summary = sample['highlights']
```

### Dataset Personnalis√©
```python
import torch
from torch.utils.data import Dataset

class SummarizationDataset(Dataset):
    def __init__(self, hf_dataset, tokenizer, max_tokens=128):
        self.dataset = hf_dataset
        self.tokenizer = tokenizer
        self.max_tokens = max_tokens
        
    def __len__(self):
        return len(self.dataset)
        
    def __getitem__(self, idx):
        item = self.dataset[idx]
        
        # Convertir article en image
        img = text_to_image(item['article'])
        img_path = f"temp_{idx}.png"
        img.save(img_path)
        
        # Tokenize target summary
        summary_tokens = self.tokenizer(
            item['highlights'],
            max_length=self.max_tokens,
            truncation=True,
            padding='max_length',
            return_tensors='pt'
        )
        
        return {
            'image_path': img_path,
            'labels': summary_tokens['input_ids'].squeeze(),
            'attention_mask': summary_tokens['attention_mask'].squeeze()
        }
```

## üîß Code Fine-Tuning

### Architecture Modifi√©e
```python
from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer
import torch

# Chargement mod√®le
model_name = "deepseek-ai/DeepSeek-OCR" 
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(
    model_name, 
    trust_remote_code=True,
    torch_dtype=torch.float16,
    device_map="auto"
)

# Freeze de l'encodeur
for name, param in model.named_parameters():
    if 'encoder' in name or 'vision' in name:
        param.requires_grad = False
        
# V√©rification
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Param√®tres entra√Ænables: {trainable_params:,}")  # ~570M
```

### Configuration Entra√Ænement
```python
training_args = TrainingArguments(
    output_dir="./deepsynth-summarizer",
    
    # Epochs & Batch
    num_train_epochs=4,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    gradient_accumulation_steps=8,  # Effective batch = 32
    
    # Learning Rate
    learning_rate=2e-5,
    warmup_steps=500,
    weight_decay=0.01,
    
    # Optimizations
    fp16=True,
    gradient_checkpointing=True,
    dataloader_pin_memory=True,
    
    # Logging & Saving
    logging_steps=25,
    save_steps=1000,
    eval_steps=500,
    evaluation_strategy="steps",
    save_strategy="steps",
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    
    # Cleanup
    remove_unused_columns=False,
    report_to="tensorboard"
)
```

### Fonction d'Entra√Ænement Custom
```python
def custom_forward(model, batch):
    """Forward pass personnalis√© pour r√©sum√©"""
    
    # Encoder images avec DeepEncoder (frozen)
    with torch.no_grad():
        visual_tokens = model.encode_images(batch['images'])  # Shape: [B, seq, hidden]
    
    # Decoder pour r√©sum√© (trainable)
    decoder_outputs = model.decoder(
        inputs_embeds=visual_tokens,
        labels=batch['labels'],
        attention_mask=batch['attention_mask']
    )
    
    return decoder_outputs

# Wrapper pour Trainer
class CustomTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        outputs = custom_forward(model, inputs)
        loss = outputs.loss
        return (loss, outputs) if return_outputs else loss

# Lancement entra√Ænement
trainer = CustomTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer,
)

trainer.train()
```

## üìà √âvaluation

### M√©triques ROUGE
```python
from datasets import load_metric
import numpy as np

rouge = load_metric('rouge')

def compute_rouge(predictions, references):
    """Calcul ROUGE-1, ROUGE-2, ROUGE-L"""
    results = rouge.compute(
        predictions=predictions,
        references=references
    )
    
    return {
        'rouge1': results['rouge1'].mid.fmeasure,
        'rouge2': results['rouge2'].mid.fmeasure, 
        'rougeL': results['rougeL'].mid.fmeasure,
    }

# √âvaluation sur test set
def evaluate_model(model, test_dataloader):
    model.eval()
    predictions = []
    references = []
    
    with torch.no_grad():
        for batch in test_dataloader:
            # G√©n√©ration
            outputs = model.generate(
                **batch,
                max_length=128,
                num_beams=4,
                early_stopping=True,
                length_penalty=2.0
            )
            
            # D√©codage
            preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)
            refs = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)
            
            predictions.extend(preds)
            references.extend(refs)
    
    return compute_rouge(predictions, references)
```

### Benchmarks Cibles
| M√©trique | CNN/DM Target | XSum Target | Notes |
|----------|---------------|-------------|--------|
| ROUGE-1 | 40-45 | 35-40 | Overlap unigrammes |
| ROUGE-2 | 18-22 | 12-16 | Overlap bigrammes |  
| ROUGE-L | 37-42 | 32-37 | Plus longue s√©quence |

## üöÄ Inf√©rence Production

### Script G√©n√©ration
```python
def generate_summary(model, tokenizer, text, max_length=128):
    """G√©n√®re r√©sum√© depuis texte"""
    
    # Conversion texte -> image
    img = text_to_image(text)
    img.save("temp_input.png")
    
    # Prompt pour r√©sum√©
    prompt = "<image>\n<|grounding|>Summarize this document briefly."
    
    # G√©n√©ration
    result = model.infer(
        tokenizer, 
        prompt=prompt,
        image_file="temp_input.png",
        max_new_tokens=max_length,
        temperature=0.7,
        do_sample=True
    )
    
    return result['result']

# Usage
summary = generate_summary(model, tokenizer, long_document)
print(f"R√©sum√©: {summary}")
```

### Optimisations vLLM
```python
# Pour d√©ploiement haute performance
from vllm import LLM, SamplingParams

llm = LLM(
    model="./deepsynth-summarizer",
    trust_remote_code=True,
    dtype="float16",
    gpu_memory_utilization=0.9,
    max_model_len=4096
)

sampling_params = SamplingParams(
    temperature=0.7,
    max_tokens=128,
    stop=["<|endoftext|>"]
)

# Batch inference
summaries = llm.generate(prompts, sampling_params)
```

## üìã Checklist Impl√©mentation

### Phase 1: Setup
- [ ] Clone repo DeepSeek-OCR
- [ ] Installation environnement Python
- [ ] Login Hugging Face + t√©l√©chargement datasets
- [ ] Test mod√®le de base sur exemple

### Phase 2: Donn√©es  
- [ ] Impl√©mentation text_to_image()
- [ ] Cr√©ation SummarizationDataset
- [ ] Split train/val/test
- [ ] V√©rification quality samples

### Phase 3: Fine-Tuning
- [ ] Freeze encodeur, unfreeze d√©codeur  
- [ ] Configuration TrainingArguments
- [ ] Lancement entra√Ænement
- [ ] Monitoring loss/m√©triques

### Phase 4: √âvaluation
- [ ] Calcul ROUGE sur test set
- [ ] Comparaison avec baselines
- [ ] Analyse qualitative outputs
- [ ] Tests edge cases

### Phase 5: Production
- [ ] Optimisation inf√©rence vLLM
- [ ] Documentation API
- [ ] Tests performance GPU
- [ ] D√©ploiement containeris√©

## üîß Debugging & Troubleshooting

### Probl√®mes Courants
1. **OOM (Out of Memory)** : R√©duire batch_size, activer gradient_checkpointing
2. **Convergence lente** : Ajuster learning_rate, warmup_steps  
3. **Qualit√© r√©sum√©s** : Tuner generation parameters (temperature, length_penalty)
4. **Images trop grandes** : Limiter r√©solution, text wrapping

### Ressources Debug
- **Issues GitHub** : https://github.com/deepseek-ai/DeepSeek-OCR/issues
- **Fine-tuning Issue** : https://github.com/deepseek-ai/DeepSeek-OCR/issues/43
- **Community Discussions** : https://huggingface.co/deepseek-ai/DeepSeek-OCR/discussions

## üìö R√©f√©rences Compl√®tes

### Papers & Research
- DeepSeek-OCR Paper: https://arxiv.org/abs/2510.18234
- LoRA vs Full Fine-tuning: https://arxiv.org/abs/2410.21228
- Compression Rate Summarization: https://arxiv.org/abs/2110.07936

### Tools & Frameworks
- Transformers: https://huggingface.co/docs/transformers/
- Datasets: https://huggingface.co/docs/datasets/
- vLLM: https://docs.vllm.ai/
- Unsloth: https://docs.unsloth.ai/

---

*Ce document contient toutes les informations n√©cessaires pour impl√©menter le fine-tuning DeepSeek-OCR pour r√©sum√© abstractif. Suivez les sections dans l'ordre pour une impl√©mentation compl√®te.*