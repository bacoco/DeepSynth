#!/usr/bin/env python3
"""
ğŸš€ Lanceur pour crÃ©er des datasets sÃ©parÃ©s par langue
CrÃ©e: deepsynth-fr, deepsynth-es, deepsynth-de, deepsynth-en-news, etc.

Usage:
    python run_separate_datasets.py
"""

import os
import sys
from pathlib import Path
from separate_datasets_builder import main as run_separate_builder

def check_environment():
    """Check if environment is properly configured."""
    print("ğŸ”§ VÃ©rification de l'environnement...")

    # Check HF_TOKEN
    hf_token = os.getenv('HF_TOKEN')
    if not hf_token:
        print("âŒ HF_TOKEN introuvable!")
        print("ğŸ’¡ Veuillez dÃ©finir votre token HuggingFace:")
        print("   export HF_TOKEN=your_token_here")
        print("   Ou l'ajouter Ã  votre fichier .env")
        return False

    print("âœ… Token HuggingFace trouvÃ©")

    # Check .env file
    env_file = Path('.env')
    if env_file.exists():
        print("âœ… Fichier .env trouvÃ©")
    else:
        print("âš ï¸  Fichier .env non trouvÃ© (optionnel)")

    return True

def show_datasets_info():
    """Show information about datasets to be created."""
    print("\\nğŸ¯ DATASETS SÃ‰PARÃ‰S Ã€ CRÃ‰ER (ORDRE DE PRIORITÃ‰)")
    print("=" * 60)
    print("ğŸ“Š Datasets de sortie:")
    print("  ğŸ¥‡ deepsynth-en-news   - CNN/DailyMail (~287k exemples) [PRIORITÃ‰ 1]")
    print("  ğŸ¥ˆ deepsynth-en-arxiv  - arXiv Scientific (~50k exemples) [PRIORITÃ‰ 2]")
    print("  ğŸ¥‰ deepsynth-en-xsum   - BBC XSum (~50k exemples) [PRIORITÃ‰ 3]")
    print("  ğŸ‡«ğŸ‡· deepsynth-fr        - MLSUM FranÃ§ais (~392k exemples) [PRIORITÃ‰ 4]")
    print("  ğŸ‡ªğŸ‡¸ deepsynth-es        - MLSUM Espagnol (~266k exemples) [PRIORITÃ‰ 5]")
    print("  ğŸ‡©ğŸ‡ª deepsynth-de        - MLSUM Allemand (~220k exemples) [PRIORITÃ‰ 6]")
    print("  ğŸ“œ deepsynth-en-legal   - BillSum Legal (~22k exemples) [PRIORITÃ‰ 7]")
    print("  " + "â”€" * 50)
    print("  ğŸ“Š TOTAL: 7 datasets sÃ©parÃ©s")

    print("\\nğŸš€ Avantages des datasets sÃ©parÃ©s:")
    print("  âœ… Un dataset par langue/domaine")
    print("  âœ… TÃ©lÃ©chargement sÃ©lectif possible")
    print("  âœ… EntraÃ®nement spÃ©cialisÃ© par langue")
    print("  âœ… Gestion plus facile des versions")
    print("  âœ… Partage ciblÃ© avec la communautÃ©")

    arxiv_limit = int(os.getenv('ARXIV_IMAGE_SAMPLES', '50000'))
    print(f"\\nâš™ï¸  Configuration arXiv: {arxiv_limit:,} Ã©chantillons max")
    print("â±ï¸  Temps estimÃ©: 6-12 heures (selon le matÃ©riel)")
    print("ğŸ’¾ Espace disque nÃ©cessaire: ~15GB temporaire")

def main():
    """Run the separate datasets pipeline."""
    print("ğŸŒ DEEPSEEK DATASETS SÃ‰PARÃ‰S PAR LANGUE")
    print("=" * 70)

    # Check environment
    if not check_environment():
        sys.exit(1)

    # Show datasets info
    show_datasets_info()

    # Confirm execution
    print("\\nâ“ PrÃªt Ã  crÃ©er les 7 datasets sÃ©parÃ©s?")
    print("   Cela va traiter ~1.29M Ã©chantillons et les uploader sur HuggingFace")

    try:
        response = input("Continuer? [y/N]: ").strip().lower()
        if response not in ['y', 'yes', 'o', 'oui']:
            print("â¹ï¸  Pipeline annulÃ© par l'utilisateur")
            sys.exit(0)
    except KeyboardInterrupt:
        print("\\nâ¹ï¸  Pipeline annulÃ© par l'utilisateur")
        sys.exit(0)

    print("\\nğŸš€ DÃ©marrage du pipeline de datasets sÃ©parÃ©s...")
    print("ğŸ’¡ Vous pouvez interrompre avec Ctrl+C et reprendre plus tard")

    try:
        # Run the separate datasets builder
        run_separate_builder()

        print("\\nğŸ‰ TOUS LES DATASETS CRÃ‰Ã‰S AVEC SUCCÃˆS!")
        print("ğŸ”— Vos datasets sont maintenant disponibles sur HuggingFace")

    except KeyboardInterrupt:
        print("\\nâ¸ï¸  Pipeline interrompu par l'utilisateur")
        print("ğŸ’¡ ProgrÃ¨s sauvegardÃ© - relancez pour reprendre")
        sys.exit(0)

    except Exception as e:
        print(f"\\nâŒ Ã‰chec du pipeline: {e}")
        print("ğŸ’¡ VÃ©rifiez l'erreur ci-dessus et relancez pour reprendre")
        sys.exit(1)

if __name__ == "__main__":
    main()
