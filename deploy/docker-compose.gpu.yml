version: '3.8'

services:
  deepsynth-trainer:
    build:
      context: ..
      dockerfile: deploy/Dockerfile
    container_name: deepsynth-trainer-gpu
    ports:
      - "5001:5000"
    volumes:
      # Mount state directory for persistence
      - ../src/apps/web/ui/state:/app/web_ui/state
      # Mount output directories
      - ../trained_model:/app/trained_model
      - ../datasets:/app/datasets
      - ../benchmarks:/app/benchmarks
      # Mount logs
      - ../logs:/app/logs
      # Mount HuggingFace cache for model persistence
      - ../huggingface_cache:/root/.cache/huggingface
    environment:
      # HuggingFace Configuration
      - HF_TOKEN=${HF_TOKEN}
      - HF_USERNAME=${HF_USERNAME}

      # Flask Configuration
      - FLASK_ENV=production
      - SECRET_KEY=${SECRET_KEY:-change-this-secret-key}
      - HOST=0.0.0.0
      - PORT=5000

      # State directory configuration
      - DEEPSYNTH_UI_STATE_DIR=/app/web_ui/state

      # CUDA Configuration for GPU training
      - CUDA_VISIBLE_DEVICES=0
      - TORCH_CUDA_ARCH_LIST=7.0;7.5;8.0;8.6;8.9;9.0

      # bitsandbytes Configuration (for QLoRA 4-bit/8-bit quantization)
      - BNB_CUDA_VERSION=124

      # Python Configuration
      - PYTHONUNBUFFERED=1

      # LoRA/PEFT Training Options (can be overridden via UI)
      # These are defaults - users can configure via web UI
      - DEFAULT_USE_LORA=false
      - DEFAULT_LORA_RANK=16
      - DEFAULT_LORA_ALPHA=32

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    restart: unless-stopped

    command: python3 -m apps.web

networks:
  default:
    name: deepsynth-network
