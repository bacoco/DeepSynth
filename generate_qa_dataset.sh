#!/bin/bash
#
# Script de g√©n√©ration one-shot pour le dataset Q&A combin√©
# Usage: ./generate_qa_dataset.sh [OPTIONS]
#
# Ce script va cr√©er UN SEUL dataset combin√© sur HuggingFace:
#   deepsynth-qa (~1.3M samples total)
#     ‚îú‚îÄ Natural Questions (~300k)
#     ‚îî‚îÄ MS MARCO (~1M)
#
# Images pr√©-g√©n√©r√©es √† r√©solution gundam (1600px)
# Source tracking: metadata.source = "natural_questions" | "ms_marco"
#
# Dur√©e estim√©e: 6-12 heures (traitement s√©quentiel)
# Taille finale: 312-624 GB compress√© sur HuggingFace
#

set -e  # Arr√™t en cas d'erreur

echo "üîç DEEPSYNTH - G√©n√©ration Dataset Q&A Combin√©"
echo "============================================================="

# Parse arguments
TEST_MODE=false
MAX_SAMPLES=""

while [[ $# -gt 0 ]]; do
    case $1 in
        --test)
            TEST_MODE=true
            shift
            ;;
        --max-samples)
            MAX_SAMPLES="--max-samples $2"
            shift 2
            ;;
        --help|-h)
            echo "Usage: $0 [OPTIONS]"
            echo ""
            echo "Options:"
            echo "  --test              Test mode (1000 samples per source)"
            echo "  --max-samples N     Custom max samples for test mode"
            echo "  --help, -h          Show this help"
            echo ""
            echo "Examples:"
            echo "  $0                         # Full generation (~1.3M samples)"
            echo "  $0 --test                  # Test with 1000 samples per source"
            echo "  $0 --max-samples 5000      # Test with 5000 samples per source"
            exit 0
            ;;
        *)
            echo "‚ùå Unknown option: $1"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
done

# V√©rifier et installer les d√©pendances si n√©cessaire
if [ ! -d "venv" ] || [ ! -f "/Library/Fonts/DejaVuSans.ttf" ]; then
    echo "‚öôÔ∏è  Installation des d√©pendances et fonts Unicode..."
    echo "   (Premi√®re ex√©cution uniquement - peut demander sudo)"
    echo ""

    if [ ! -x "./setup.sh" ]; then
        chmod +x setup.sh
    fi

    ./setup.sh

    echo ""
    echo "‚úÖ Installation termin√©e"
    echo "============================================================="
    echo ""
fi

# Activer l'environnement virtuel
if [ -f "venv/bin/activate" ]; then
    source venv/bin/activate
    echo "‚úÖ Environnement virtuel activ√©"
else
    echo "‚ö†Ô∏è  Pas d'environnement virtuel d√©tect√©"
    echo "   Utilisation de Python syst√®me"
fi

echo ""

# V√©rifier que le fichier .env existe
if [ ! -f .env ]; then
    echo "‚ùå Erreur: Fichier .env introuvable"
    echo "üí° Copiez .env.example vers .env et configurez HF_TOKEN"
    exit 1
fi

# V√©rifier HF_TOKEN
if ! grep -q "HF_TOKEN=" .env; then
    echo "‚ùå Erreur: HF_TOKEN non configur√© dans .env"
    echo "üí° Ajoutez votre token HuggingFace dans le fichier .env"
    exit 1
fi

# Afficher la configuration
echo "‚úÖ Configuration d√©tect√©e:"
grep "HF_USERNAME=" .env || echo "‚ö†Ô∏è  HF_USERNAME non d√©fini"

echo ""

# Mode test ou production
if [ "$TEST_MODE" = true ]; then
    echo "üß™ MODE TEST"
    echo "============================================================="
    echo "üìä Traitement: ~2,000 samples (1,000 par source)"
    echo "‚è±Ô∏è  Temps estim√©: 5-10 minutes"
    echo "üíæ Taille finale: ~500 MB"
    echo ""
    TEST_FLAG="--test $MAX_SAMPLES"
else
    echo "üöÄ MODE PRODUCTION"
    echo "============================================================="
    echo "üìä Traitement: ~1.3M samples total"
    echo "   ‚Ä¢ Natural Questions: ~300k samples"
    echo "   ‚Ä¢ MS MARCO: ~1M samples"
    echo ""
    echo "‚è±Ô∏è  Temps estim√©: 6-12 heures"
    echo "üíæ Taille finale: 312-624 GB compress√©"
    echo ""
    echo "üí° NOTES:"
    echo "  ‚Ä¢ Images pr√©-g√©n√©r√©es √† r√©solution gundam (1600px)"
    echo "  ‚Ä¢ Extraction contextuelle intelligente (Natural Questions)"
    echo "  ‚Ä¢ Upload incr√©mental tous les 5000 samples"
    echo "  ‚Ä¢ Interruption/reprise support√©e (Ctrl+C)"
    echo ""
    echo "‚ö†Ô∏è  AVERTISSEMENT: Ceci va prendre plusieurs heures"

    read -p "   Continuer? (o/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[OoYy]$ ]]; then
        echo "‚ùå Annul√© par l'utilisateur"
        exit 0
    fi

    TEST_FLAG=""
fi

echo ""
echo "üöÄ D√âMARRAGE DE LA G√âN√âRATION..."
echo "============================================================="
echo ""

# Lancer le script Python
chmod +x generate_qa_dataset.py
PYTHONPATH=./src python3 generate_qa_dataset.py $TEST_FLAG

EXIT_CODE=$?

echo ""
echo "============================================================="
if [ $EXIT_CODE -eq 0 ]; then
    echo "‚úÖ G√âN√âRATION TERMIN√âE AVEC SUCC√àS!"
    echo ""
    echo "üìä Dataset disponible sur:"
    echo "   https://huggingface.co/datasets/$(grep HF_USERNAME= .env | cut -d= -f2)/deepsynth-qa"
    echo ""
    echo "üí° Pour utiliser le dataset:"
    echo "   from datasets import load_dataset"
    echo "   dataset = load_dataset('$(grep HF_USERNAME= .env | cut -d= -f2)/deepsynth-qa')"
    echo ""
    echo "   # Filtrer par source"
    echo "   nq = dataset.filter(lambda x: x['metadata']['source'] == 'natural_questions')"
    echo "   marco = dataset.filter(lambda x: x['metadata']['source'] == 'ms_marco')"
else
    echo "‚ö†Ô∏è  La g√©n√©ration s'est termin√©e avec des erreurs (code: $EXIT_CODE)"
    echo "üí° Consultez 'generate_qa_dataset.log' pour les d√©tails"
fi
echo "============================================================="

exit $EXIT_CODE
